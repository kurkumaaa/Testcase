{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129482f6",
   "metadata": {},
   "source": [
    "# DataPreprocessor: Класс для обработки и трансформации табличных данных\n",
    "\n",
    "Этот notebook демонстрирует возможности класса **DataPreprocessor**, который выполняет базовые операции по очистке и трансформации табличных данных.\n",
    "\n",
    "## Основные возможности:\n",
    "1. **remove_missing()** - удаление столбцов с высокой долей пропусков и заполнение оставшихся\n",
    "2. **encode_categorical()** - One-Hot кодирование категориальных переменных\n",
    "3. **normalize_numeric()** - нормализация и стандартизация числовых признаков\n",
    "4. **fit_transform()** - применение всех трансформаций в одной операции\n",
    "5. **transform()** - применение сохранённого pipeline к новым данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d730069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Установка стиля для графиков\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Библиотеки успешно загружены!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка класса DataPreprocessor из модуля\n",
    "import sys\n",
    "sys.path.insert(0, r'g:\\Testcase')\n",
    "\n",
    "from data_preprocessor import DataPreprocessor\n",
    "\n",
    "print(\"Класс DataPreprocessor успешно загружен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae55ca",
   "metadata": {},
   "source": [
    "## Шаг 1: Загрузка и исследование датасета\n",
    "\n",
    "Используем датасет **California Housing** из scikit-learn. Этот датасет содержит информацию о домах в Калифорнии с признаками, включая географические координаты, среднюю стоимость дома, количество комнат и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета California Housing\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "df['Price'] = housing.target\n",
    "\n",
    "# Информация о датасете\n",
    "print(\"=\" * 60)\n",
    "print(\"ИНФОРМАЦИЯ О ДАТАСЕТЕ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nФорма датасета: {df.shape}\")\n",
    "print(f\"\\nПервые 5 строк:\")\n",
    "print(df.head())\n",
    "print(f\"\\nТипы данных:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nОсновная статистика:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление пропусков для демонстрации очистки данных\n",
    "np.random.seed(42)\n",
    "\n",
    "# Добавляем случайные пропуски\n",
    "df_with_missing = df.copy()\n",
    "\n",
    "# Столбец с 60% пропусков (будет удалён)\n",
    "missing_indices = np.random.choice(len(df_with_missing), size=int(len(df_with_missing) * 0.6), replace=False)\n",
    "df_with_missing.loc[missing_indices, 'Latitude'] = np.nan\n",
    "\n",
    "# Столбец с 20% пропусков (будет заполнен)\n",
    "missing_indices = np.random.choice(len(df_with_missing), size=int(len(df_with_missing) * 0.2), replace=False)\n",
    "df_with_missing.loc[missing_indices, 'Longitude'] = np.nan\n",
    "\n",
    "print(\"\\nДатасет с добавленными пропусками:\")\n",
    "print(f\"Процент пропусков по столбцам:\")\n",
    "print((df_with_missing.isnull().sum() / len(df_with_missing) * 100).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b63a5",
   "metadata": {},
   "source": [
    "## Шаг 2: Основная демонстрация работы класса DataPreprocessor\n",
    "\n",
    "Создаём экземпляр класса и применяем полный pipeline обработки данных с методом `fit_transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8527da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание экземпляра класса DataPreprocessor\n",
    "preprocessor = DataPreprocessor(df_with_missing)\n",
    "\n",
    "# Применение полного pipeline с методом fit_transform()\n",
    "df_processed = preprocessor.fit_transform(\n",
    "    remove_missing_threshold=0.5,  # Удалять столбцы с 50%+ пропусков\n",
    "    fill_method='mean',             # Заполнять пропуски средним значением\n",
    "    normalize_method='minmax'        # Использовать Min-Max нормализацию\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0545cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод результатов преобразования\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"РЕЗУЛЬТАТЫ ПРЕОБРАЗОВАНИЯ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nФорма обработанного датасета: {df_processed.shape}\")\n",
    "print(f\"\\nПервые 5 строк обработанного датасета:\")\n",
    "print(df_processed.head())\n",
    "print(f\"\\nОсновная статистика после обработки:\")\n",
    "print(df_processed.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65484edd",
   "metadata": {},
   "source": [
    "## Шаг 3: Информация о применённых преобразованиях\n",
    "\n",
    "Получаем подробную информацию об операциях, выполненных при обработке данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение информации о преобразованиях\n",
    "preprocessing_info = preprocessor.get_preprocessing_info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ИНФОРМАЦИЯ О ПРЕОБРАЗОВАНИЯХ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. ИСХОДНЫЕ СТОЛБЦЫ ({len(preprocessing_info['original_columns'])} шт.):\")\n",
    "print(preprocessing_info['original_columns'])\n",
    "\n",
    "print(f\"\\n2. УДАЛЁННЫЕ СТОЛБЦЫ ({len(preprocessing_info['removed_columns'])} шт.):\")\n",
    "print(preprocessing_info['removed_columns'] if preprocessing_info['removed_columns'] else \"Нет\")\n",
    "\n",
    "print(f\"\\n3. КАТЕГОРИАЛЬНЫЕ СТОЛБЦЫ ({len(preprocessing_info['categorical_columns'])} шт.):\")\n",
    "print(preprocessing_info['categorical_columns'] if preprocessing_info['categorical_columns'] else \"Нет\")\n",
    "\n",
    "print(f\"\\n4. ЧИСЛОВЫЕ СТОЛБЦЫ ({len(preprocessing_info['numeric_columns'])} шт.):\")\n",
    "print(preprocessing_info['numeric_columns'])\n",
    "\n",
    "print(f\"\\n5. МЕТОД НОРМАЛИЗАЦИИ: {preprocessing_info['scaler_method']}\")\n",
    "\n",
    "print(f\"\\n6. ЗНАЧЕНИЯ ДЛЯ ЗАПОЛНЕНИЯ ПРОПУСКОВ:\")\n",
    "for col, val in preprocessing_info['fill_values'].items():\n",
    "    print(f\"   {col}: {val:.4f}\")\n",
    "\n",
    "print(f\"\\n7. ИТОГОВАЯ ФОРМА ДАТАСЕТА: {preprocessing_info['data_shape']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29d97f",
   "metadata": {},
   "source": [
    "## Шаг 4: Сравнение методов нормализации\n",
    "\n",
    "Демонстрация работы двух методов нормализации: Min-Max и стандартизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение Min-Max нормализации\n",
    "preprocessor_minmax = DataPreprocessor(df_with_missing)\n",
    "df_minmax = preprocessor_minmax.fit_transform(\n",
    "    remove_missing_threshold=0.5,\n",
    "    fill_method='mean',\n",
    "    normalize_method='minmax'\n",
    ")\n",
    "\n",
    "print(\"\\nОбработка с методом Min-Max нормализации завершена!\")\n",
    "print(f\"Форма датасета: {df_minmax.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение стандартизации (Z-score normalization)\n",
    "preprocessor_std = DataPreprocessor(df_with_missing)\n",
    "df_std = preprocessor_std.fit_transform(\n",
    "    remove_missing_threshold=0.5,\n",
    "    fill_method='mean',\n",
    "    normalize_method='std'\n",
    ")\n",
    "\n",
    "print(\"\\nОбработка с методом стандартизации завершена!\")\n",
    "print(f\"Форма датасета: {df_std.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48bffec",
   "metadata": {},
   "source": [
    "## Шаг 5: Визуализация результатов нормализации\n",
    "\n",
    "Сравнение распределений признаков при разных методах нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d05c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем несколько числовых столбцов для сравнения\n",
    "numeric_cols_to_plot = ['MedInc', 'HouseAge', 'AveRooms']\n",
    "\n",
    "fig, axes = plt.subplots(len(numeric_cols_to_plot), 3, figsize=(15, 10))\n",
    "fig.suptitle('Сравнение методов нормализации', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, col in enumerate(numeric_cols_to_plot):\n",
    "    # Исходные данные (с заполненными пропусками)\n",
    "    preprocessor_temp = DataPreprocessor(df_with_missing)\n",
    "    preprocessor_temp.remove_missing(threshold=0.5, fill_method='mean')\n",
    "    \n",
    "    axes[idx, 0].hist(preprocessor_temp.df[col], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx, 0].set_title(f'{col}\\n(Исходные данные)', fontweight='bold')\n",
    "    axes[idx, 0].set_ylabel('Частота')\n",
    "    \n",
    "    # Min-Max нормализация\n",
    "    axes[idx, 1].hist(df_minmax[col], bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "    axes[idx, 1].set_title(f'{col}\\n(Min-Max нормализация)', fontweight='bold')\n",
    "    \n",
    "    # Стандартизация\n",
    "    axes[idx, 2].hist(df_std[col], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[idx, 2].set_title(f'{col}\\n(Стандартизация)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Визуализация завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43957a23",
   "metadata": {},
   "source": [
    "## Шаг 6: Применение сохранённого pipeline к новым данным\n",
    "\n",
    "Демонстрация метода `transform()` для применения того же набора преобразований к новому датасету (например, тестовым данным)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на тренировочный и тестовый наборы\n",
    "train_data = df_with_missing.iloc[:int(len(df_with_missing) * 0.8)]\n",
    "test_data = df_with_missing.iloc[int(len(df_with_missing) * 0.8):]\n",
    "\n",
    "print(f\"Размер тренировочного набора: {train_data.shape}\")\n",
    "print(f\"Размер тестового набора: {test_data.shape}\")\n",
    "\n",
    "# Создание и обучение preprocessor на тренировочных данных\n",
    "train_preprocessor = DataPreprocessor(train_data)\n",
    "train_processed = train_preprocessor.fit_transform(\n",
    "    remove_missing_threshold=0.5,\n",
    "    fill_method='mean',\n",
    "    normalize_method='minmax'\n",
    ")\n",
    "\n",
    "print(f\"\\nЗначение Price (средняя стоимость) после нормализации:\")\n",
    "print(f\"Min: {train_processed['Price'].min():.4f}, Max: {train_processed['Price'].max():.4f}\")\n",
    "print(f\"Mean: {train_processed['Price'].mean():.4f}, Median: {train_processed['Price'].median():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f6e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение сохранённого pipeline к тестовым данным\n",
    "test_processed = train_preprocessor.transform(test_data)\n",
    "\n",
    "print(f\"\\nПрименение pipeline к тестовым данным:\")\n",
    "print(f\"Форма тестового набора до обработки: {test_data.shape}\")\n",
    "print(f\"Форма тестового набора после обработки: {test_processed.shape}\")\n",
    "\n",
    "print(f\"\\nПервые 5 строк обработанного тестового набора:\")\n",
    "print(test_processed.head())\n",
    "\n",
    "print(f\"\\nСравнение статистики тестового набора (должны быть в пределах [0, 1] для Min-Max):\")\n",
    "print(test_processed.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe49eaf2",
   "metadata": {},
   "source": [
    "## Шаг 7: Обработка ошибок и валидация параметров\n",
    "\n",
    "Демонстрация работы обработки ошибок при неправильных входных параметрах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Демонстрация обработки ошибок\n",
    "print(\"=\" * 60)\n",
    "print(\"ДЕМОНСТРАЦИЯ ОБРАБОТКИ ОШИБОК\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ошибка 1: Передача не-DataFrame\n",
    "print(\"\\n1. Попытка создать DataPreprocessor с не-DataFrame объектом:\")\n",
    "try:\n",
    "    bad_preprocessor = DataPreprocessor([1, 2, 3])\n",
    "except TypeError as e:\n",
    "    print(f\"   ✓ Перехвачена ошибка: {e}\")\n",
    "\n",
    "# Ошибка 2: Пустой DataFrame\n",
    "print(\"\\n2. Попытка создать DataPreprocessor с пустым DataFrame:\")\n",
    "try:\n",
    "    empty_df = pd.DataFrame()\n",
    "    bad_preprocessor = DataPreprocessor(empty_df)\n",
    "except ValueError as e:\n",
    "    print(f\"   ✓ Перехвачена ошибка: {e}\")\n",
    "\n",
    "# Ошибка 3: Неправильный threshold\n",
    "print(\"\\n3. Попытка использовать threshold вне диапазона [0, 1]:\")\n",
    "try:\n",
    "    preprocessor = DataPreprocessor(df_with_missing)\n",
    "    preprocessor.remove_missing(threshold=1.5)\n",
    "except ValueError as e:\n",
    "    print(f\"   ✓ Перехвачена ошибка: {e}\")\n",
    "\n",
    "# Ошибка 4: Неправильный метод нормализации\n",
    "print(\"\\n4. Попытка использовать неправильный метод нормализации:\")\n",
    "try:\n",
    "    preprocessor = DataPreprocessor(df_with_missing)\n",
    "    preprocessor.normalize_numeric(method='invalid_method')\n",
    "except ValueError as e:\n",
    "    print(f\"   ✓ Перехвачена ошибка: {e}\")\n",
    "\n",
    "# Ошибка 5: Неправильный fill_method\n",
    "print(\"\\n5. Попытка использовать неправильный метод заполнения:\")\n",
    "try:\n",
    "    preprocessor = DataPreprocessor(df_with_missing)\n",
    "    preprocessor.remove_missing(fill_method='invalid')\n",
    "except ValueError as e:\n",
    "    print(f\"   ✓ Перехвачена ошибка: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Все ошибки успешно обработаны!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a4771c",
   "metadata": {},
   "source": [
    "## Шаг 8: Воздействие порога пропусков на результат\n",
    "\n",
    "Сравнение результатов при разных значениях threshold для удаления столбцов с пропусками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование разных значений threshold\n",
    "thresholds = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ВОЗДЕЙСТВИЕ THRESHOLD НА КОЛИЧЕСТВО УДАЛЁННЫХ СТОЛБЦОВ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    try:\n",
    "        preprocessor = DataPreprocessor(df_with_missing)\n",
    "        preprocessor.remove_missing(threshold=threshold, fill_method='mean')\n",
    "        \n",
    "        removed_count = len(preprocessor.removed_columns)\n",
    "        remaining_count = len(preprocessor.df.columns)\n",
    "        \n",
    "        results.append({\n",
    "            'Threshold': threshold,\n",
    "            'Удалено столбцов': removed_count,\n",
    "            'Осталось столбцов': remaining_count,\n",
    "            'Удалённые': ', '.join(preprocessor.removed_columns) if preprocessor.removed_columns else 'Нет'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при threshold={threshold}: {e}\")\n",
    "\n",
    "# Вывод результатов в виде таблицы\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8319a25",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "### Основные возможности класса DataPreprocessor:\n",
    "\n",
    "1. **Удаление столбцов с пропусками** (`remove_missing`)\n",
    "   - Автоматически идентифицирует и удаляет столбцы с высокой долей пропусков\n",
    "   - Заполняет оставшиеся пропуски средним значением, медианой или модой\n",
    "   - Параметр `threshold` позволяет гибко управлять порогом удаления\n",
    "\n",
    "2. **One-Hot кодирование** (`encode_categorical`)\n",
    "   - Автоматически преобразует категориальные (строковые) переменные в бинарные признаки\n",
    "   - Сохраняет информацию о всех созданных новых столбцах\n",
    "\n",
    "3. **Нормализация признаков** (`normalize_numeric`)\n",
    "   - Поддерживает Min-Max нормализацию (масштабирование на [0, 1])\n",
    "   - Поддерживает стандартизацию (Z-score нормализация)\n",
    "   - Применяется ко всем числовым столбцам\n",
    "\n",
    "4. **Комплексный pipeline** (`fit_transform`)\n",
    "   - Последовательно применяет все три преобразования\n",
    "   - Сохраняет параметры для применения к новым данным\n",
    "\n",
    "5. **Переиспользуемость** (`transform`)\n",
    "   - Позволяет применять одинаковые преобразования к тестовым данным\n",
    "   - Гарантирует консистентность между тренировочным и тестовым наборами\n",
    "\n",
    "### Применение:\n",
    "- Подготовка данных для машинного обучения\n",
    "- Нормализация признаков перед использованием алгоритмов, чувствительных к масштабу\n",
    "- Обработка пропущенных значений в реальных датасетах"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
